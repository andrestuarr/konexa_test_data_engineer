# Konexa Test - Data Engineer

Este repositorio presenta una soluciÃ³n integral para una prueba tÃ©cnica de **IngenierÃ­a de Datos**, basada en una **arquitectura orientada a eventos** en Google Cloud Platform. La soluciÃ³n aborda tres requerimientos clave mediante el uso de Terraform, Cloud Functions, Composer (Airflow) y BigQuery.

---

## ğŸ¯ Objetivo

1. Detectar automÃ¡ticamente la carga de un archivo en un bucket de GCS.
2. Ejecutar una Cloud Function que reaccione al evento.
3. Lanzar un DAG en Cloud Composer que importe el archivo en BigQuery y realice una transformaciÃ³n de datos.

---

## âš™ï¸ Arquitectura de la soluciÃ³n

Se implementa una **arquitectura event-driven** (basada en eventos) que automatiza completamente el procesamiento del archivo:

<img src="imagenes/arquitectura.jpg" alt="Arquitectura de la soluciÃ³n" width="750"/>

### Flujo:

1. âœ… **Carga de archivo a GCS**  
   Un archivo `.csv` es subido manual o automÃ¡ticamente a un bucket de Cloud Storage, lo que genera un evento.

2. ğŸš€ **Cloud Function (trigger por evento)**  
   La funciÃ³n se activa por el evento, extrae los metadatos del archivo y lanza un DAG en Composer, pasando los parÃ¡metros necesarios.

3. ğŸ“ˆ **DAG en Cloud Composer (Airflow)**  
   El DAG realiza las siguientes acciones:
   - Verifica o crea el dataset en BigQuery.
   - Carga el archivo desde GCS a una tabla temporal en BigQuery.
   - Aplica una transformaciÃ³n SQL para tipificar correctamente los datos y almacenarlos en una tabla final.

<img src="imagenes/dag.png" alt="Diagrama del DAG ejecutado exitosamente" width="750"/>

---

## ğŸ“ Estructura del proyecto

```plaintext
â”œâ”€â”€ cloud_functions/            # CÃ³digo de la Cloud Function
â”‚   â””â”€â”€ main.py
|   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ composer/                   # DAG de Airflow
â”‚   â””â”€â”€ dag_process.py
â”‚
â”œâ”€â”€ infrastructure/             # Infraestructura como cÃ³digo (Terraform)
â”‚   â”œâ”€â”€ modules
â”‚   â”‚    â”œâ”€â”€ cloud_functions
â”‚   â”‚    â”œâ”€â”€ cloud_storage
â”‚   â”‚    â”œâ”€â”€ composer
â”‚   â”‚    â””â”€â”€ iam
|   â”œâ”€â”€ main.tf
â”‚   â”œâ”€â”€ variables.tf
â”‚   â”œâ”€â”€ providers.tf
â”‚   â””â”€â”€ outputs.tf
â”‚
â””â”€â”€ imagenes/                   # Diagramas explicativos
    â”œâ”€â”€ arquitectura.jpg
    â””â”€â”€ dag.png
```


---

## ğŸ› ï¸ TecnologÃ­as utilizadas

- **Google Cloud Platform (GCP)**  
  - Cloud Storage  
  - Cloud Functions  
  - Cloud Composer (Apache Airflow)  
  - BigQuery  

- **Terraform** â€” Infraestructura como cÃ³digo  
- **GitHub Actions** â€” AutomatizaciÃ³n del CI/CD  
- **Python** â€” LÃ³gica de la Cloud Function y el DAG

---

## ğŸš€ Despliegue en otro proyecto

1. **Clonar este repositorio** y configurar las credenciales de GCP.  
   Debes contar con una cuenta de servicio con permisos para desplegar recursos (Storage, Functions, Composer, etc.). Guarda el JSON como secreto en GitHub con el nombre `GCP_CREDS`.

2. **Configurar variables de entorno**  
   Edita las variables `PROJECT_ID` y `REGION` en los secretos o variables del pipeline. AdemÃ¡s, revisa `variables.tf` para evitar conflictos con nombres de buckets o recursos.

3. **Desplegar con Terraform**  
   AsegÃºrate de que las siguientes APIs estÃ©n habilitadas: Cloud Storage, Eventarc, Cloud Functions, Cloud Composer, BigQuery.

   ```bash
   cd infrastructure
   terraform init
   terraform apply
4. **Probar despliegue automÃ¡tico**  
   Realiza un cambio en alguno de los siguientes componentes para activar el pipeline CI/CD:
   - CÃ³digo del DAG (`composer/dags`)
   - CÃ³digo de la Cloud Function (`modules/cloud_function`)
   - Infraestructura (`infrastructure`)

   âš ï¸ Cambios en `modules/cloud_storage/function.zip` no activarÃ¡n el pipeline, ya que estÃ¡n ignorados por configuraciÃ³n.

   ```bash
   git add .
   git commit -m "Prueba de despliegue automÃ¡tico"
   git push origin main
<img src="imagenes/despliegue.png" alt="DescripciÃ³n" width="900">

5. **Probar el flujo de procesamiento de datos**  
   Sube el archivo `Telecom_Customers_Churn.csv` al bucket creado por Terraform. Esto inicia automÃ¡ticamente el pipeline de procesamiento:

   - âœ… La **Cloud Function** se activa al detectar la subida del archivo.
   - ğŸš€ Lanza un **DAG en Cloud Composer**, pasÃ¡ndole los metadatos del evento.
   - ğŸ“ˆ El **DAG ejecuta las siguientes tareas**:
     - Verifica si el **dataset** en BigQuery existe; si no, lo crea.
     - Carga el archivo CSV desde GCS a una tabla **temporal** en BigQuery, con todos los campos como `STRING`.
     - Aplica una transformaciÃ³n SQL que **castea las columnas a sus tipos correctos** usando un esquema `.json` predefinido almacenado en GCS (tambiÃ©n creado con la IaC).

---


## ğŸ¯ Pregunta 4:

### a. Preguntas al Ã¡rea de negocio

- Â¿CuÃ¡l es la prioridad de atenciÃ³n entre los registros generados?
- Â¿Existe una ventana de tiempo lÃ­mite para ejecutar las llamadas una vez generado el registro?
- Â¿QuÃ© acciones deben tomarse en caso de fallos en la entrega (por ejemplo, reintentos, alertas, etc.)?
- Â¿Se necesita trazabilidad de cada llamada y su estado (Ã©xito, error, reintento)?
- Â¿El volumen de registros puede aumentar en el futuro?

### b. Preguntas al proveedor de la API

- Â¿CuÃ¡l es el mecanismo de autenticaciÃ³n requerido por la API?
- Â¿Existen restricciones adicionales (por IP, headers, horarios, etc.)?
- Â¿QuÃ© tipos de errores puede devolver la API y cÃ³mo manejarlos adecuadamente?
- Â¿Existen cuotas diarias o lÃ­mites mensuales ademÃ¡s del lÃ­mite por segundo?
- Â¿Soporta reintentos o debe manejarse completamente desde el cliente?

## âš™ï¸ Arquitectura de la soluciÃ³n

La siguiente arquitectura considera los requerimientos mencionados, con foco en control de tasa de solicitudes y procesamiento asincrÃ³nico confiable. Algunos componentes podrÃ­an ajustarse tras una revisiÃ³n detallada con las Ã¡reas involucradas y el proveedor del servicio.

<img src="imagenes/arquitectura_call_center.jpg" alt="DescripciÃ³n" width="900">

## ğŸ§© Componentes
1. **Servicio Generador de Solicitudes de Llamada**
Orquesta el procesamiento inicial de los registros generados cada hora y los envÃ­a a la cola de procesamiento.

2. **Call Request Rate Control (Cloud Tasks)**
Utiliza Cloud Tasks para garantizar que no se exceda el lÃ­mite de 10 requests/segundo. Encola automÃ¡ticamente las solicitudes y las despacha segÃºn la tasa permitida.

3. **Call Center Worker (Cloud Run)**
Servicio backend responsable de consumir tareas desde la cola y realizar las llamadas a travÃ©s de la API. TambiÃ©n almacena logs y estados de cada solicitud en Firestore para trazabilidad.

4. **Webhook Receiver (Cloud Functions)**
Punto de entrada para notificaciones asincrÃ³nicas de la API (por ejemplo, confirmaciÃ³n de llamada o resultados). Permite actualizar el estado en Firestore.

5. Firestore
Base de datos NoSQL utilizada para registrar logs de solicitudes, errores y estados de cada llamada, permitiendo seguimiento y auditorÃ­a.


## âœ… JustificaciÃ³n de la arquitectura
- **Escalabilidad automÃ¡tica**: El uso de servicios serverless como Cloud Run y Cloud Functions permite escalar segÃºn demanda sin intervenciÃ³n manual.

- **Control de flujo robusto**: Cloud Tasks permite controlar de forma precisa la tasa de envÃ­o hacia la API, alineÃ¡ndose con las limitaciones del proveedor.

- **Procesamiento resiliente y asincrÃ³nico**: El desacoplamiento de componentes garantiza tolerancia a fallos, reintentos y persistencia.

- **Observabilidad**: Con Firestore como almacenamiento de estado, se puede consultar fÃ¡cilmente el estado de cada llamada y aplicar dashboards o alertas si es necesario.

- **Extensibilidad**: La arquitectura permite incluir nuevas fuentes de registros, diferentes mecanismos de notificaciÃ³n, o integrar servicios adicionales (por ejemplo, BigQuery para analÃ­tica posterior).

