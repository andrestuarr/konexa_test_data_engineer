# Konexa Test - Data Engineer

Este proyecto es una soluciÃ³n integral para una prueba tÃ©cnica de ingenierÃ­a de datos. La soluciÃ³n aborda tres requerimientos principales mediante una arquitectura basada en eventos:

## ğŸ§© Objetivo

1. Procesar automÃ¡ticamente un archivo cuando se carga a un bucket en GCS.
2. Desplegar automÃ¡ticamente una Cloud Function para manejar el procesamiento.
3. Ejecutar un DAG en Cloud Composer para cargar el archivo en BigQuery y aplicar una transformaciÃ³n.

---

## âš™ï¸ Arquitectura de la soluciÃ³n

La soluciÃ³n implementa una **arquitectura orientada a eventos** que cubre las tres preguntas:

<img src="imagenes/arquitectura.jpg" alt="DescripciÃ³n" width="750">


1. âœ… **Subida de archivo a GCS**  
   Dispara un evento que activa una Cloud Function.

2. ğŸš€ **Cloud Function (Event Trigger)**  
   La funciÃ³n obtiene los metadatos del archivo y lanza un DAG en Cloud Composer.

3. ğŸ“ˆ **DAG en Composer (Airflow)**  
   El DAG:
   - Asegura la existencia del dataset en BigQuery.
   - Carga el archivo desde GCS a BigQuery.
   - Ejecuta una transformaciÃ³n SQL directamente sobre los datos cargados.



   <img src="imagenes/dag.png" alt="DescripciÃ³n" width="750">

---

## ğŸ“ Estructura del proyecto



---

## ğŸ› ï¸ TecnologÃ­as usadas

- **Google Cloud Platform (GCP)**  
  - Cloud Functions  
  - Cloud Storage  
  - BigQuery  
  - Cloud Composer (Airflow)

- **Terraform** â€” Para Infraestructura como CÃ³digo  
- **GitHub Actions** â€” Para CI/CD automatizado  
- **Python** â€” LÃ³gica de Cloud Function y DAG

---

## ğŸš€ Despliegue

1. Clonar el repositorio y configurar credenciales GCP.
2. Editar las variables en los archivos `variables.tf`.
3. Ejecutar los comandos de Terraform:
   ```bash
   terraform init
   terraform apply